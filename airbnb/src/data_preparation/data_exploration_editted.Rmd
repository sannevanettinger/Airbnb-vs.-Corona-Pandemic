---
title: "Data Exploration"
author: 'Team 2: Sanne, Demi, Claudia, Rob & Jurg'
date: "2/15/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
# loading packages
install.packages("plyr")
install.packages("dplyr")
install.packages("tidyverse")
install.packages("ggplot2")
install.packages("readr")
install.packages("googledrive")
install.packages("caret")
library(plyr)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(readr)
library(googledrive)
# more to come ...
```

## Data Exploration

This is an R Markdown document in which the data for the project is explored. In this document you will find out how all of the raw data files are programmatically downloaded from the internet. Besides that, information about the content of the raw data files and the definition of the variables are provided. 

The data is downloaded from insideairbnb.com and provides detailed listings data from AirBnB in cities from all around the world. Since the data is available in quarters of the year, 4 raw data files are imported into Rstudio. 

### Preparing the data
Since the data is split up into 4 raw data files, and need to be merged for the whole research project, these raw data files need to be prepared before merging.

```{r importing multiple datasets from Google Drive, message=FALSE, warning=FALSE}
# importing the multiple datasets from the Google Drive

data_id <- "1AzdybwMX-2QRfcolBv-2xT-5XKUeQpRhLBXtH1n47qM"
drive_download(as_id(data_id), path = "out_file.csv", overwrite = TRUE)
df <- read.csv("out_file.csv")

urls <- as.character(df$link)

datasets <- lapply(urls, function(url) {
  print(paste0("Now downloading ... ", url))
  city = tolower(as.character(df$city[match(url, df$link)]))
  
  res = read.csv(url)
  res$city <- city
  return(res)
})

combined_data = do.call('rbind', datasets)

```

```{r export raw data file to Excel/CSV}

```


```{r importing 4 raw csv data files (old version), message=FALSE, warning=FALSE, include=FALSE}
# importing the 4 raw data files
listings_london_qrt4 <- read_csv("http://data.insideairbnb.com/united-kingdom/england/london/2021-12-07/data/listings.csv.gz")
listings_london_qrt3 <- read_csv("http://data.insideairbnb.com/united-kingdom/england/london/2021-09-09/data/listings.csv.gz")
listings_london_qrt2 <- read_csv("http://data.insideairbnb.com/united-kingdom/england/london/2021-06-07/data/listings.csv.gz")
listings_london_qrt1 <- read_csv("http://data.insideairbnb.com/united-kingdom/england/london/2021-03-05/data/listings.csv.gz")

```



```{r}
# First Scaling the variables before merging

```


#### Creating a new variable: quarter
To distinguish the different raw data files in the merged data file, a new variable is created: quarter. This variable indicates the original data file by a number (1, 2, 3 or 4).  

```{r creating new variable: quarter, message=FALSE}
# creating a new variable: quarter. This indicates the original data file (1, 2, 3, 4)

listings_london_qrt1$quarter <- c(1)
listings_london_qrt2$quarter <- c(2)
listings_london_qrt3$quarter <- c(3)
listings_london_qrt4$quarter <- c(4)
```

#### Merging the 4 data files into 1 data file
Merge all the 4 data files into 1 data file to get started with the data exploration.
**How can this be combined into 1 piece of code?**

```{r merging the 4 data files into 1 data file, message=FALSE, warning=FALSE, include=FALSE}
# Merging the 4 data files into 1 data file.
listings_london <- rbind(listings_london_qrt1,
            listings_london_qrt2,
            listings_london_qrt3,
            listings_london_qrt4)
```

```{r rearranging the order of the rows, echo=TRUE}

# rearranging the order of the columns in such a way that quarter is the second column
listings_london <- listings_london %>% 
  select(id, quarter, listing_url:reviews_per_month)


# Rearranging the order of the rows. 
listings_london <- listings_london %>% 
  arrange(id, quarter)


# Take a look at the new dataset
head(listings_london)

```

```{r rearranging the order of the rows, echo=TRUE}
# Rearranging the order of the rows. 
listings_london <- listings_london %>% 
  arrange(id, quarter)

# Take a look at the new dataset
head(listings_london)
```


### Research

Before moving on to exploring the data, the idea of the research is provided once again: 

**Research question**: Which types of rooms in which neighborhoods benefited the most from the Corona Pandemic in London, United Kingdom?

***Variables***:

*Neighborhoods (31)*

- Rating score
- Number of listings
- Price increase

*Room Types (4)*

- Rating score
- Number of listings
- Price increase

### Let's take a look at the data

This summary provides an insight into the raw data files that has been imported. We can check what the column names of the variables are, if the variables have the right class and check whether there are missing values in the dataset. 

```{r summary of whole dataset, message=FALSE}
summary(listings_london)
```

To come back to our variables, we can now assign the column names to the variables.

**Variables**:

- Neighbourhood:      neighbourhood_cleansed
- Room types:         room_type
- Rating scores:      review_score_rating
- Price increase:     price

# Dit klopt niet er is geen variabel die het aantal boekingen telt. Mischien focussen op prijs?
- Number of bookings: calculated_host_listings_count
                      **OR** host_listings_count

As you can see in the summary, the variable price is imported as a character. This has to be changed to a numeric variable.

```{r change price variable, warning=FALSE}
# remove the dollar sign and commas (for prices above thousand)
listings_london$price <- gsub('[$,]', '', listings_london$price)

# changing price variable from character to numeric
listings_london$price <- as.numeric(listings_london$price)

# check for the results
class(listings_london$price)
```

```{r removing missing values from rating score, include=FALSE}
# How to deal with the missing values? Just delete them or what is the idea?

# discuss tomorrow. It may be that there is a underlying construct on why people did not made a review. So I would not delete them. 

```


```{r}
Remove columns that we don't need

```

### Exploring the data

Looking into the (in)dependent variables of our research project to get a feel for the dataset.

```{r summaries of the independent variables, echo=TRUE}
# summary of the price variable
summary(listings_london$price)

# summary of the rating score
summary(listings_london$review_scores_rating)

# summary of the number of listings
summary(listings_london$host_listings_count)

# table of the number of rooms per neighbourhood
table(listings_london$neighbourhood_cleansed)

# table of the number of room types
table(listings_london$room_type)
```

```{r}
# Detecting outliers
```


The rating score variable has a lot of missing values (NA's), 85.842 missing in total. Since this is an important variable in the research project, it has to be dealt with. **How?**
The rating score is also measured in two different ways, namely on a 0-100 (quarter 1) scale and 0-5 (quarter 2-4) scale. Because of this, the mean score on this variable can not be measured and has to be changed. Either to the 0-100 scale or the 0-5 scale. 

# we have to do standardization I think. 

It looks like there is one or more outliers for the variable host_listings_count (ook calculated_host_listings_count hebben deze outliers.). This variable has nearly 2.000 missing values, which needs to be dealt with.

# We can trimm the data. Delete about 1% of the data outliers

## To Do

List of things that needs to be done:

- Renaming the column names, some are hard to write in the code.
- Detecting the outliers for the number of bookings variable through a simple plot. #truncation/trimming
- Deal with the missing values of the key variables in our project.
- Changing the measurement scale of the rating score variable. # standardization
- Deleting (?) the columns that we do not need.
- Visualizing using plots
